{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510ee71e-e9b9-40e6-a906-b2c97de2d662",
   "metadata": {},
   "source": [
    "# Implimentation of GradientDescent on Multiple_Dimension on BostonDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67578d61-507e-4a44-9781-b26c45231308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets #imported Boston datasets as it have multidimensional input featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88ec233f-8337-4c8d-8d5c-014ff2b72ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston=datasets.load_boston()\n",
    "print(type(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f84219ec-b3fe-4440-8311-f30d0e28fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "X=boston.data\n",
    "Y=boston.target\n",
    "print(type(X))\n",
    "print(type(Y))\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0f8aa05-54e7-47c7-84e2-5ccfe87b6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT  \n",
      "count  506.000000  \n",
      "mean    12.653063  \n",
      "std      7.141062  \n",
      "min      1.730000  \n",
      "25%      6.950000  \n",
      "50%     11.360000  \n",
      "75%     16.955000  \n",
      "max     37.970000  \n",
      "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
      "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
      "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
      "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
      "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
      "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "0       15.3  396.90   4.98  \n",
      "1       17.8  396.90   9.14  \n",
      "2       17.8  392.83   4.03  \n",
      "3       18.7  394.63   2.94  \n",
      "4       18.7  396.90   5.33  \n",
      "..       ...     ...    ...  \n",
      "501     21.0  391.99   9.67  \n",
      "502     21.0  396.90   9.08  \n",
      "503     21.0  396.90   5.64  \n",
      "504     21.0  393.45   6.48  \n",
      "505     21.0  396.90   7.88  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(X)#It would create 2Dtable: (Rows,Coloumn),in which X was form of numpyArray and as you know from oandas if there is no coloumn headings the by-deafult first-row becomes that \n",
    "print(boston.feature_names)#Now this would be pur coloumnHeader,repreents different types of input(features of input)\n",
    "df.columns=boston.feature_names#Now those feeaureNames are columnHeaders\n",
    "print(df.describe())#Describes dataRepresentation Heavily\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd792a42-c5e1-4ec6-9490-30e48969014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379,)\n",
      "(127, 13)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=model_selection.train_test_split(X,Y)\n",
    "\n",
    "#Sizes\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c721f6e-518f-40f9-8705-f017cc734a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "(13,)\n",
      "[[2.87500e-02 2.80000e+01 1.50400e+01 ... 1.82000e+01 3.96330e+02\n",
      "  6.21000e+00]\n",
      " [6.12700e-02 4.00000e+01 6.41000e+00 ... 1.76000e+01 3.93450e+02\n",
      "  4.16000e+00]\n",
      " [3.76619e+01 0.00000e+00 1.81000e+01 ... 2.02000e+01 1.88200e+01\n",
      "  1.45200e+01]\n",
      " ...\n",
      " [1.23290e-01 0.00000e+00 1.00100e+01 ... 1.78000e+01 3.94950e+02\n",
      "  1.62100e+01]\n",
      " [4.98100e-02 2.10000e+01 5.64000e+00 ... 1.68000e+01 3.96900e+02\n",
      "  8.43000e+00]\n",
      " [1.51902e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 3.88450e+02\n",
      "  3.32000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(X_train[0][:].shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534cf09-3c0a-4cfa-b93f-7556e5b35307",
   "metadata": {},
   "source": [
    "# GradientDescent-Parameters:\n",
    "### 1)Data-TrainingData & TestingData\n",
    "### 2)Learning_Rate(alpha)\n",
    "### 3)Number_Of_Iterations\n",
    "### 4)INstead of m and c ,Passed m-array for m in each row including c at last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eee1c04e-0359-4c60-b140-05b598094d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here in multi-variable , we would pass the all m in array-formate including c inside it at last  \n",
    "\n",
    "#Defining function which would calculate new m and c for a single step\n",
    "def step_gradient(X_train,Y_train,learning_rate,m,c):\n",
    "    # m=np.array([0 for i in range(13)])\n",
    "    m_slope=[0 for i in range(13)]\n",
    "    c_slope=0\n",
    "    M=len(X_train)\n",
    "    # x=np.array([1 for i in range(13)])\n",
    "    # print(x.shape, m.shape,X_train[0][:].shape)\n",
    "\n",
    "    for i in range(M):\n",
    "        y=Y_train[i]\n",
    "        # it will copy all 13 element from X_train and also put 1 at the end that is at 14th element\n",
    "        # x=np.appened(X_train[i][:],1)\n",
    "        x = X_train[i][:] \n",
    "        # print(x.shape)\n",
    "        for j in range(13):\n",
    "            m_slope[j]+=(-2/M)*(y-np.dot(m,x)-c)*x[j]\n",
    "        c_slope+=(-2/M)*(y-np.dot(m,x)-c)\n",
    "\n",
    "    new_m=[m[i]-learning_rate*m_slope[i] for i in range(13)]\n",
    "    new_c=c-learning_rate*c_slope\n",
    "    return (new_m,new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e95ca3b3-bd33-4319-9f08-e3f5aa8f9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining GradientDescent-function as gd\n",
    "def gd(X_train,Y_train,learning_rate,num_iterations):      \n",
    "    #At first we should have random values of m and c\n",
    "    m=[0 for i in range(13)]\n",
    "    c=0\n",
    "    for i in range(num_iterations):#We should update these m,c values for number iteration times\n",
    "        m,c=step_gradient(X_train,Y_train,learning_rate,m,c) #Another function made which would calculate sinleStep-GradientDescent\n",
    "        current_cost = cost(X_train, Y_train, m, c)  # Calculate cost for current parameters\n",
    "        print(f\"Iteration {i+1}, Cost: {current_cost}\")\n",
    "    return (m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b91b1b6-6f80-448a-9209-ea9036f2b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining costFunction which could return the instantenousCost function\n",
    "def cost(X_train,Y_train,m,c):\n",
    "    total_cost=0\n",
    "    cost=0\n",
    "    M=len(X_train)\n",
    "    for i in range(M):\n",
    "        y=Y_train[i]\n",
    "        x=X_train[i][:]\n",
    "        cost+=((y-m*x-c)**2)\n",
    "    total_cost=1/M*(np.sum(cost))\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33c97205-3763-4092-9c59-5dabdcf514a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined a function where the resepctive parameters are passed and called GradoentFunction as \"gd\" \n",
    "def run():\n",
    "    learning_rate=0.0001\n",
    "    num_iterations=10\n",
    "    m,c=gd(X_train,Y_train,learning_rate,num_iterations)\n",
    "    print(m,c)\n",
    "    return m,c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19653b50-caea-4f69-94bc-aa52e8ca54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Cost: 891270.5433661814\n",
      "Iteration 2, Cost: 3463553261.690834\n",
      "Iteration 3, Cost: 12886357323351.625\n",
      "Iteration 4, Cost: 4.791175359514849e+16\n",
      "Iteration 5, Cost: 1.7812143533254122e+20\n",
      "Iteration 6, Cost: 6.621987922949535e+23\n",
      "Iteration 7, Cost: 2.4618436240216514e+27\n",
      "Iteration 8, Cost: 9.152348209990673e+30\n",
      "Iteration 9, Cost: 3.4025507087038487e+34\n",
      "Iteration 10, Cost: 1.2649596648871205e+38\n",
      "[-212132747206217.94, -535741205857928.4, -580024553550216.5, -3188689724438.823, -27507036366850.918, -303263321140716.9, -3426543117355162.5, -174868474479004.16, -525090916527883.94, -2.1185904306502624e+16, -902423699334882.2, -1.726991934642757e+16, -642139109814538.0] -48475524334159.766\n"
     ]
    }
   ],
   "source": [
    "m,c=run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
